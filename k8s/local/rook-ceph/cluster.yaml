# Rook-Ceph Cluster Configuration
# This creates a minimal Ceph cluster for testing S3 Manager
#
# IMPORTANT: This is a minimal configuration for testing/development.
# For production, see https://rook.io/docs/rook/latest/CRDs/Cluster/ceph-cluster-crd/
#
# Usage:
#   kubectl apply -f cluster.yaml
#
# Prerequisites:
#   - Rook operator must be running
#   - At least 3 nodes with available disks or use useAllDevices: true

---
apiVersion: ceph.rook.io/v1
kind: CephCluster
metadata:
  name: rook-ceph
  namespace: rook-ceph
spec:
  # Ceph version to use (Rook v1.19+ requires Ceph v19.2.0+)
  cephVersion:
    image: quay.io/ceph/ceph:v19.2.0
    allowUnsupported: false
  
  # Data directory on host nodes
  dataDirHostPath: /var/lib/rook
  
  # Skip upgrade checks (for testing)
  skipUpgradeChecks: false
  continueUpgradeAfterChecksEvenIfNotHealthy: false
  
  # Wait for healthy OSDs before creating new ones
  waitTimeoutForHealthyOSDInMinutes: 10
  
  # Monitor settings
  mon:
    count: 3
    allowMultiplePerNode: true
  
  # Manager settings
  mgr:
    count: 2
    allowMultiplePerNode: true
    modules:
    - name: pg_autoscaler
      enabled: true
  
  # Dashboard (Ceph UI)
  dashboard:
    enabled: true
    ssl: false
  
  # Monitoring
  monitoring:
    enabled: false
  
  # Network configuration
  network:
    provider: host
  
  # Crash collector for debugging
  crashCollector:
    disable: false
  
  # Log collector
  logCollector:
    enabled: false
  
  # Clean up policy on deletion
  cleanupPolicy:
    confirmation: ""
    sanitizeDisks:
      method: quick
      dataSource: zero
      iteration: 1
    allowUninstallWithVolumes: false
  
  # Storage configuration
  storage:
    # Use all available devices (for testing)
    useAllDevices: true
    useAllNodes: true
    
    # Or specify devices explicitly:
    # useAllDevices: false
    # deviceFilter: "^sd[b-z]"
    # nodes:
    # - name: "node1"
    #   devices:
    #   - name: "sdb"
    # - name: "node2"
    #   devices:
    #   - name: "sdb"
    # - name: "node3"
    #   devices:
    #   - name: "sdb"
    
    config:
      osdsPerDevice: "1"
  
  # Resource requests/limits for Ceph daemons
  resources:
    mon:
      limits:
        cpu: "1000m"
        memory: "2Gi"
      requests:
        cpu: "500m"
        memory: "1Gi"
    osd:
      limits:
        cpu: "2000m"
        memory: "4Gi"
      requests:
        cpu: "1000m"
        memory: "2Gi"
    mgr:
      limits:
        cpu: "1000m"
        memory: "1Gi"
      requests:
        cpu: "500m"
        memory: "512Mi"
  
  # Disruption management
  disruptionManagement:
    managePodBudgets: true
    osdMaintenanceTimeout: 30
    pgHealthCheckTimeout: 0
  
  # Priority class names
  priorityClassNames:
    mon: system-node-critical
    osd: system-node-critical
    mgr: system-cluster-critical

---
# Optional: Configure Ceph toolbox for debugging
# Uncomment to deploy:
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: rook-ceph-tools
#   namespace: rook-ceph
#   labels:
#     app: rook-ceph-tools
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: rook-ceph-tools
#   template:
#     metadata:
#       labels:
#         app: rook-ceph-tools
#     spec:
#       dnsPolicy: ClusterFirstWithHostNet
#       containers:
#       - name: rook-ceph-tools
#         image: rook/ceph:v1.19.2
#         command: ["/bin/bash"]
#         args: ["-m", "-c", "/usr/local/bin/toolbox.sh"]
#         env:
#         - name: ROOK_CEPH_USERNAME
#           valueFrom:
#             secretKeyRef:
#               name: rook-ceph-mon
#               key: ceph-username
#         - name: ROOK_CEPH_SECRET
#           valueFrom:
#             secretKeyRef:
#               name: rook-ceph-mon
#               key: ceph-secret
#         volumeMounts:
#         - mountPath: /etc/ceph
#           name: ceph-config
#         - mountPath: /etc/rook
#           name: mon-endpoint-volume
#       volumes:
#       - name: ceph-config
#         emptyDir: {}
#       - name: mon-endpoint-volume
#         configMap:
#           name: rook-ceph-mon-endpoints
#           items:
#           - key: data
#             path: mon-endpoints
